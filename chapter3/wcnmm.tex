\section{Introduction}
Computational models in neuroscience have advanced to the point where untangling neural signals observed at the macroscopic scale in terms of underlying complex neural mechanisms and their values is now possible \cite{wilson_is_2015}). As nonlinear behavior is inevitably encountered at the microscopic scale of individual neurons, nonlinear neural mass models (NMMs) have emerged as a powerful approach to balance interpretability and biological relevance of computational models. Such models summarize the state of locally interacting neuronal populations with few parameters and a conversion from mean excitation level to mean population response \cite{freeman_tutorial_1992}. The conversion is typically performed via a nonlinear sigmoid function, whereas the mean firing rates, connection profiles, and membrane potentials are parameterized mathematically to model the lumped activity of particular brain regions\cite{LopesdaSilva1974, robinson_prediction_2001, Valdes1999}. The Wilson-Cowan single oscillator model \cite{Wilson1972} has evolved into a family of macroscopic NMMs in recent literature; with derivations for neocortical dynamics \cite{cowan_wilsoncowan_2016}, controllability of brain networks \cite{muldoon_stimulation-based_2016}, biomarkers in disease \cite{Zimmermann2018}, and second order statistics of observed brain signals \cite{Deco2009, abeysuriya_biophysical_2018, singh_estimation_2020, byrne_next-generation_2019, wang_inversion_2019}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.75\textwidth]{../figures/chapter3/oscillator_unit.png}
    \caption{Illustration of a Wilson-Cowan oscillator unit.}
    \caption*{\textbf{A}: Local excitatory-inhibitory subpopulation structure with long range excitation only to the excitatory population. \textbf{B}: Oscillatory time course with default parameter settings as listed in Table \ref{tab:oscillator_parameters}, showing inhibitory population slightly lagging behind excitatory activity. \textbf{C}: Numerical simulation showing that the model is a single frequency oscillator, and at the current parameter regime, there exists a limit cycle stationary point at $E = 0.2$ and $ I = 0.1$. The number of stationary points and their behavior is subject to change depending on the initial conditions of the system.}
    \label{fig:unit}
\end{figure}

% Removed and merged with next paragraph
%In a rare occurrence of public introspection amongst computational neuroscientists, Wilson and Niv's work \cite{wilson_is_2015} questioned whether model fitting is necessary for model-based analysis of fMRI. They addressed the weakness of models having free parameters, and the results of the analysis depend on how free parameters are set. While their work was limited to the context of reinforcement learning and a single learning rate parameter, their conclusion is generalizable to the wider model-based neuroscience field: precise identification of parameters is not always necessary, and it is hard to identify neural correlates with model-based analysis due to sensitivity to parameters. More recently, Hartoyo et al. \cite{hartoyo_parameter_2019} disseminated the problem of unidentifiabiliy in whole brain models, where different parameters combinations can generate similar model predictions, especially in higher order multi-parameter dynamical systems. It has long been known that fitting of an unidentifiable model to data results in large uncertainties, out of the 22 unknown parameters from the linearized network model implemented by Hartoyo et al., only one parameter was found to be identifiable when fitted to EEG data. Nonetheless, the computational neuroscience field pushed the limit of neuron population level mean field models and extended them to describe neural activity at the whole brain scale.

% Unsolved problem and why is this a problem? 
Despite the prolific use of NMMs for whole brain model-based analysis and the promise of inferring biophysical parameters from observed macroscopic signals, they are still not widely used in practical settings. An introspective  study by some of the leaders in the field questioned whether model fitting is necessary for model-based analysis of fMRI \cite{wilson_is_2015}. In this study, Wilson and Niv addressed the weakness of models having free parameters, and noted that the results depend on how free parameters are set. While their work was limited to the context of reinforcement learning and a single learning rate parameter, their conclusion is generalizable to the wider model-based neuroscience field: precise identification of parameters is not always necessary, but it is hard to identify neural correlates with model-based analysis due to sensitivity to parameters. More recently, Hartoyo et al. \cite{hartoyo_parameter_2019} disseminated the problem of unidentifiabiliy in whole brain models, where different parameter combinations can generate similar model predictions, especially in higher order multi-parameter dynamical systems. It has long been known that fitting of an unidentifiable model to data results in large uncertainties; indeed, out of the 22 unknown parameters from the linearized network model implemented by Hartoyo et al., only one parameter was found to be identifiable when fitted to EEG data. 

The essential factor underlying the challenge of inference is the nonlinear nature of NMMs, whose coupling via the connectome leads to well characterized chaotic behavior. This then leads to difficulties in parameter inference and generalizable decoding of neural mechanisms. The saddle point and Hopf bifurcation behavior of the Wilson-Cowan model were described by the original work of Wilson \& Cowan \cite{Wilson1972}, the Virtual Brain \cite{sanz-leon_mathematical_2015} and in reviews \cite{breakspear_dynamic_2017}. A common observation in such nonlinear systems is that large parameter regimes give uninteresting steady-state behavior, but exhibit discontinuous and abrupt shits to interesting oscillating, unstable or chaotic behavior when network coupling or external driving force parameters push the system over the Hopf bifurcation. During parameter inference, discontinuous switching between regimes and model behavior leads to a non-convex cost function with many local minima. One way to avoid these issues is to set all biophysiological parameters for local populations in a NMM to be near an appropriate Hopf bifurcation point that gives the correct frequency (e.g. alpha band). This is then followed by optimization of the remaining few (global) parameters to fit the second order functional connectivity (FC) metrics such as pairwise correlation or synchrony \cite{Zimmermann2018, Deco2009, abeysuriya_biophysical_2018, wang_inversion_2019, demirtas_hierarchical_2019, honey_predicting_2009}. Frequently the last piece is achieved via manual grid search. Table \ref{tab:nmm_pubs} summarizes relevant recent studies that follow this approach.

\begin{table}
 \caption{Whole Brain Neural Mass Model Parameter Inference Publications and their performance.}
 \caption*{This table does not include publications with whole brain mean field models or mechanistic models of neural activity.}
  \centering
  \begin{tabular*}{\textwidth}{llll}
    \toprule
    \cmidrule(r){1-2}
    Name & Modality  & Target  & Accuracy \\
    \midrule
    Zimmerman et al. \cite{Zimmermann2018} & fMRI & Correlation FC & $r=0.57$  \\
    Honey et al. \cite{honey_predicting_2009} & fMRI & Correlation FC & $ r=0.48$ \\
    Demirtas et al. \cite{demirtas_hierarchical_2019} & fMRI & Correlation FC & $r=0.743$ \\
    Wang et al. \cite{wang_inversion_2019} & fMRI & Correlation FC & $r=0.46$ \\
    Schirner et al. \cite{schirner_inferring_2018} & fMRI & BOLD Time series & $r=0.50$ \\
    Falcon et al. \cite{falcon_virtual_2015} & fMRI  & Correlation FC  &  $r = 0.29$  \\
    Abeysuriya et al. \cite{abeysuriya_biophysical_2018} & MEG & Synchrony FC & $r = 0.48$ \\
    Deco et al. (2017) \cite{deco_single_2017}  & MEG & Envelope FC & $r=0.45$ \\
    Deco et al. (2009) \cite{Deco2009} & fMRI & Kuramoto order parameter & Not reported \\
    Hadida et al. \cite{hadida_bayesian_2018} & MEG & Envelope FC & $r=0.42$ \\
    \bottomrule
  \end{tabular*}
  \label{tab:nmm_pubs}
\end{table}

Notwithstanding these challenges, recent NMM approaches have proliferated and demonstrated inference in healthy and diseased brains \cite{honey_dynamical_2008,alstott_modeling_2009,haan_activity_2012,yang_functional_2016,Zimmermann2018,singh_estimation_2020}. Therefore it is opportune and topical to ask, in which respects such methods may be considered useful, and where would they fail? Is it sufficient to select parameters that can only reproduce 2nd order covariances rather than the primary signal? In that case, what can the manually selected parameters of the local mass tell us about biological mechanisms and processes in play? Can the above 2-step optimization (local neural masses fit to desired brain rhythm, and coupling parameters to FC) give a good or even unique solution? Finally and most importantly, current methods ignore the regional variations in frequency spectra of brain activity; hence it would be necessary to understand whether the model parameters optimized for FC metrics translate well to the frequency spectrum?

In this work, we will investigate the difficulties faced in gradient descent based approaches to parameter inference of current networked NMMs. We present a systematic examination of the Wilson-Cowan model, chosen as a canonical exemplar of the approach taken by most recent models. First, we examine the performance of a single Wilson-Cowan oscillator unit when fitting to broadband spectra. We implemented Markov Chain Monte Carlo (MCMC) sampling to perform all inference. Our first goal is to test whether MCMC sampling of the local Wilson-Cowan model can converge to a reasonable posterior distribution for its parameters. We then implement the whole-brain networked Wilson-Cowan model, where local neural masses are coupled to each other via fiber connectivity, with a global coupling constant that controls the weight given to local versus remote signal.  Again we use MCMC to sample the posterior distribution of the parameters. The likelihood function here is based, like prior studies, on 2nd order statistics of MEG data, like  coherence-based functional connectivity (COH) and amplitude envelope correlation (AEC). Our second goal is to verify whether the global parameters can be appropriately optimized in order to reproduce these FC matrices, and whether those inferred parameters also then produce the correct set of regional power spectra spanning the entire frequency range, from delta to gamma.

\section{Methods}

\subsection{Experimental Procedure}

\subsubsection{Study Cohort}
We acquired MEG, anatomical MRI, and diffusion MRI for 36 healthy adult subjects (23 males, 13 females; 26 left-handed, 10 right-handed; mean age 21.75 years (range: 7–51 years). All study procedures were approved by the institutional review board at the University of California at San Francisco (UCSF) and are in accordance with the ethics standards of the Helsinki Declaration of 1975 as revised in 2008.

\subsubsection{MRI}
A 3 Tesla TIM Trio MR scanner (Siemens, Erlangen, Germany) was used to perform MRI using a 32-channel phased-array radiofrequency head coil. High-resolution MRI of each subject's brain was collected using an axial 3D magnetization prepared rapid-acquisition gradient-echo (MPRAGE) T1-weighted sequence (echo time [TE] = 1.64 ms, repetition time [TR] = 2,530 ms, TI = 1,200 ms, flip angle of 7°) with a 256-mm field of view (FOV), and 160 1.0-mm contiguous partitions at a 256×256 matrix. Whole-brain diffusion weighted images were collected at b = 1000s/mm2 with 30 directions using 2-mm voxel resolution in-plane and through-plane. The T1-weighted images were then parcellated into 68 cortical and 18 subcortical regions using the Desikan-Killiany atlas available in Freesurfer \cite{Fischl2012, Desikan2006}, the voxel labels were used to identify modeled dipoles in MEG source Reconstruction.

\subsubsection{Structural Connectivity Network}
To construct high resolution average connectivity matrices with the same Desikan-Killiany parcellations, we obtained openly available data from the Human Connectome Project \cite{McNab2013}. Subject specific structural connectivity was computed using diffusion MRI data: \emph{Bedpostx} was used to determine the orientation of brain fibers in conjunction witht \emph{flirt}, as implemented in the FSL software \cite{jenkinson_fsl_2012}. In order to determine the elements of the adjacency matrix, we performed tractography using \emph{probtrackx2}. We initiated 4,000 streamlines from each seed voxel corresponding to a cortical or subcortical gray matter structure and tracked how many of these streamlines reached a target gray matter structure. The weighted connection between the two structures $c_{j,k}$ was defined as the number of streamlines initiated by voxels in region $j$ that reach any voxels in region $k$, normalized by the sum of the source and target region volumes ($c_{j,k} = \frac{streamlines}{v_j + v_k}$). This normalization prevents large brain regions from having high connectivity simply due to having initiated or received many streamlines.

\begin{figure}[ht]
    \centering
    \captionsetup{justification=centerlast}
    \includegraphics[width=\textwidth]{../figures/chapter3/oscillator_full_10hz.png}
    \caption{MCMC sampling of posterior distribution when maximizing likelihood to average MEG power spectrum ($L_{\textrm{PSD}}$).}
    \caption*{Corner plot of the posterior marginal distributions for parameters $\tau_e$, $\tau_i$, and $P$ when initiating from default values (\textbf{A}) or Hopf bifurcation point (\textbf{B}) showing the probability densities of accepted parameter samples. The mean, and bounds for 95\% confidence intervals are shown on top of each column for each parameter. \textbf{C} and \textbf{D} illustrates the average MEG spectrum (green) alongside the oscillator model spectra (blue) simulated with the posterior mean values shown from the corner plots above.}
    \label{fig:oscillator_full}
\end{figure}

\subsubsection{MEG Acquisition and Source Reconstruction}
MEG recordings were acquired at UCSF using a 275-channel CTF Omega 2000 whole-head MEG system from VSM MedTech (Coquitlam, BC, Canada). All subjects were instructed to keep their eyes closed for 5 min while their MEGs were recorded at a sampling frequency of 1,200 Hz. Then, all recordings were downsampled to 600 Hz and digitally filtered to remove DC offset and other noisy artifact outside of the 1 to 160Hz bandpass range prior to source reconstructions. To "invert" our sensor space recordings to the MRI voxels, we used an adaptive spatial filtering algorithm from the NUTMEG software tool \cite{dalal_nutmeg:_2004}. To prepare for source localization, all MEG sensor locations were co-registered to each subject's anatomical MRI scans. The lead field (forward model) for each subject was calculated in NUTMEG using a multiple local-spheres head model (three-orientation lead field) and an 8mm voxel grid which generated more than 5,000 dipole sources, all sources were normalized to have a norm of 1. Finally, the MEG recordings were projected into source space using a beamformer spatial filter. Source estimates tend to have a bias towards superficial currents and the estimates are more error-prone when we approach subcortical regions, therefore, only the sources belonging to the 68 cortical regions were selected to be averaged around the centroid.

\subsubsection{Functional Connectivity}
To analyze static functional connectivity in the MEG data and in the model, we computed both $\alpha$ band coherence (COH) and amplitude envelope correlation (AEC) with MNE Python's connectivity module implementations \cite{GramfortEtAl2013a}. First, multi-taper power spectrum densities were computed with digital prolate spheroidal sequences (DPSS) windows, and adaptive weights were used to combine the tapered spectra into full power spectral densities (PSDs). Finally for data in parcellated brain regions $i$ and $j$, with estimated cross- and power spectral densities $S_{ij}$ and $S_{ii}$, $S_{jj}$, the coherence between regions $i$ and $j$ is given by: 

\begin{equation}
    C_{ij} = \frac{|E[S_{ij}]|}{\sqrt{E[S_{ii}] * E[S_{jj}]}}
\end{equation}

To compute the amplitude envelope correlation (AEC), narrow band MEG time courses were obtained by bandpass filtering between 8 and 12 Hz. Hilbert transformed analytic signal corresponding to the orthogonalized narrow band time courses were computed to account for spatial leakage and zero-lag correlations. As recommended by \cite{hipp_large-scale_2012, brookes_measuring_2011, deco_single_2017}, MEG resting-state FC is maximized by solely considering ultra-slow fluctuations of the amplitude envelope. Therefore, a 4th order low-pass Butterworth filter at 0.2Hz is implemented, obtaining an envelope time course with alpha band carrier frequency, Finally, the Pearson correlation between every pair of envelope time courses were computed.

\subsubsection{Model Parameter Inference with Markov Chain Monte Carlo Sampler}
Markov Chain Monte Carlo (MCMC) sampling is a valuable tool in modern machine learning techniques, with Metropolis-Hasting \cite{hastings_monte_1970} and Gibbs \cite{geman_stochastic_1984, gelfand_sampling-based_1990} samplers being the most widely used algorithms. Such algorithms allow marginalization over parameters and use a Bayesian inference framework to estimate the full posterior distribution of model parameters. Specifically, the samplers are initialized at a chosen initial parameter value and is allowed to randomly step to nearby new values. The Markov chain over the sampling process evaluates whether the random steps should be accepted as potential solutions, with the goal of accepting samples based on a probability distribution that resembles the true stationary distribution resembling some data, and the mean of our accepted samples converging to the true expected value given enough Markov chain steps. To condition a probability distribution over model parameters $\theta$, we define a conditional likelihood function based on a Gaussian:

\begin{equation}
\label{eq:ll}
    L_{\Psi} = \log P(y | \theta)_{\Psi} = - \frac{1}{2} \sum_n [\frac{(\Psi_{\textrm{MEG}} - \Psi_{\textrm{model}})^2}{\sigma_n^2} + \log \sigma_n^2] \\
\end{equation}

where the log likelihood function $L_{\Psi}$ evaluates the difference between the observed data and the model's output for a metric $\Psi$: $L_{\textrm{PSD}}$, $L_{\textrm{C}}$, and $L_{\textrm{AEC}}$, corresponding to power spectral density, coherence, and amplitude envelope correlation, respectively.

For all model parameters $\theta$, we will use uniform ("uninformative") distributions as prior distributions, which will allow samplers to randomly explore the nearby parameters from its initial positions. As the samplers accept and reject newly sampled parameters, a full posterior probability distribution will be constructed, and the mean of this posterior distribution will be the most probable model parameters given the observed data.

\subsection{Wilson-Cowan Local Oscillator Model}

\begin{table}[]
    \centering
    \caption{Default parameters for the Wilson-Cowan oscillator model.}
    \caption*{The excitatory driving force $P$ and time constants $\tau_e$ and $\tau_i$ are inferred during our experimentation, and their initial values are shown here. All default values are set such that small inputs would cause the system to oscillate (near the Hopf bifurcation point).}
    \begin{tabular}{lll}
    \toprule
    \cmidrule(r){1-2}
    Symbol                 &  Physiological Parameter     & Value \\
    \midrule
    $a_e$, $a_i$           &  Response function max slope & 1.3, 2 \\
    $\theta_e$, $\theta_i$ &  Response function threshold & 4, 3.7 \\
    $c_1$, $c_2$           &  Excitatory coupling         & 16, 12 \\
    $c_3$, $c_4$           &  Inhibitory coupling         & 15, 3  \\
    $r_e$, $r_i$           &  Refractory periods          & 1, 1 \\
    $\tau_e$, $\tau_i$     &  Time constants              & 8 ms \\
    $P$                    &  External driving force      & 1.25 \\
    \bottomrule
    \end{tabular}
    \label{tab:oscillator_parameters}
\end{table}

The original derivation of the single oscillator Wilson-Cowan model is illustrated in \cite{Wilson1972}. This model is capable of producing oscillations of the excitatory and inhibitory populations typically seen in MEG. Many variants of this model exist; here we employ an extremely simplified model described in (\cite{Deco2009}), to highlight the importance of delays and coupling in the brain. For local oscillations, two subpopulation of neurons are considered: an excitatory subpopulation ($E$), and an inhibitory subpopulation ($I$) that tends to drive the system towards quiescence. Given static local subpopulation couplings, varying firing amongst the two subpopulation of neurons, and an external driving force controlling the excitation, the model is able to describe the temporal dynamics of a mean field of neurons. Additionally, Wilson \& Cowan introduced "response functions" where local firing-thresholds within each subpopulation control the response of initially quiescent neurons to excitation. They are modeled as sigmoidal functions:   

\begin{equation}
\label{eq:sigmoid}
S(x) = \frac{1}{1+e^{-a(x-b)}} - \frac{1}{1+e^{a b}}
\end{equation}

Where $a$ and $b$ are parameters detailing the sigmoidal response function's maximum slope and the position of maximum slope respectively. Finally, with $E(t)$ and $I(t)$ representing the ratio of neurons firing for the two subpopulations respectively, the original Wilson-Cowan model is defined as:

\begin{equation}
    \label{eq:wco_ex}
\tau_e \frac{dE_{j}(t)}{dt} = -E_{j}(t) + (1 - r_e E_{j}(t)) \, S_e(c_1 E_{j}(t) - c_2 I_{j}(t) + P) + \epsilon_{j} (t)
\end{equation}

\begin{equation}
\label{eq:wco_in}
\tau_i \frac{dI_{j}(t)}{dt} = -I_{j}(t) + (1 - r_i I_{j}(t)) \, S_i(c_3 E_{j}(t) - c_4 I_{j}(t)) + \epsilon_{j} (t)
\end{equation}

Where $\tau_e$ and $\tau_i$ are time constants, the length of the refractory periods are parameterized by $r_e$ and $r_i$, $c_{1,2,3,4}$ are parameters representing the strength of excitatory-excitatory, inhibitory-excitatory, excitatory-inhibitory, and inhibitory-inhibitory connections respectively. The quantity $\epsilon_{j} (t)$ is Gaussian noise; following Muldoon et al. \cite{muldoon_stimulation-based_2016}, the noise is scaled by $0.00001$ to ensure accuracy in step-wise integration of the differential equations. Lastly, $P$ is the external driving force pushing neurons out of quiescence. In this formulation, the time constants $\tau_e$ and $\tau_i$ together with the external drive parameter $P$ controls the Hopf bifucation point of this model, and all local connection strengths are held constant during inference. A summary of all model parameters is listed in Table \ref{tab:oscillator_parameters} and the model's time course and stationary points are illustrated in Figure \ref{fig:unit}. The parameter settings listed here are consistent with the limit cycle settings as published originally by Wilson \& Cowan \cite{Wilson1972} and the network controllability work by Muldoon et al.  \cite{muldoon_stimulation-based_2016}.

\subsection{Network Extension of Wilson-Cowan Model}
To extend this single frequency oscillator model to the whole brain network, a term resembling long range white matter connections given by the connectivity matrix $A$ is introduced:

\begin{equation}
    \label{eq:wcn_ex}
\tau_e \frac{dE_{j}(t)}{dt} = -E_{j}(t) + (1 - r_e E_{j}(t)) \, S_e(c_1 E_{j}(t) - c_2 I_{j}(t) + c_5 \sum_{k} A_{jk} E_{k}(t - \tau_d^k) + P) + \epsilon_{j} (t)
\end{equation}

\begin{equation}
\label{eq:wcn_in}
\tau_i \frac{dI_{j}(t)}{dt} = -I_{j}(t) + (1 - r_i I_{j}(t)) \, S_i(c_3 E_{j}(t) - c_4 I_{j}(t)) + \epsilon_{j} (t)
\end{equation}

Here, the connectome delay term $\tau_d^k$ accounts for propagation time between distant brain regions, and is proportional to the fiber distance between them. Following prior literature \cite{muldoon_stimulation-based_2016} the model is pushed into an oscillatory regime by setting either $P$ or coupling strength ($c_5$) beyond the Hopf bifurcation point. Therefore,  like all pre-existing literature, only the global parameters that affect the dynamics in the default local parameter regime are inferred. 

The network model's simulation is complicated by the delay introduced by long range connections at each time step. In (\cite{hadida_bayesian_2018}), this problem was simplified by simulating without noise and the use of an average propagation delay. However, they still encountered quadratic increases in complexity and doubling in computation time. Specifically, at each time step size $h$, the sum of delay terms in each equation needs to be computed at time $t$ and $t+h$, and interpolated for each unique delay values between the current time step and the maximum delay. This step size is subject to further decrease if a noise term is introduced to the equations, which further increases computational cost. Additionally, initialization of delayed nonlinear system of equations is a sensitive operation. Delayed systems require a smooth function for initialization to be defined over $[t_0 - \tau_{max} t_0]$, where $t_0$ is the initial time and $\tau_{max}$ is the largest delay. Additionally, the history before time point $t_0$ should itself be a solution of the system, which makes this circular and impossible. There are no good work-arounds to this problem, hence following \cite{hadida_bayesian_2018}, we set the initial conditions for all brain regions to be constant and nodes are initially disconnected from the network for a period of time equal to maximum delay. Additionally in our implementation, we interpolate past solutions for all unique delays in our network and the full solution with an adaptive-step Runge-Kutta integrater of order 8 \cite{hairer_analysis_2008}.

\section{Results}

\subsection{Oscillator Model Performance}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{../figures/chapter3/gridsearch_fullfit.png}
    \caption{Exhaustive grid search of the local oscillator model.}
    \caption*{Parameters affecting Hopf bifurcation point and oscillatory frequency were iteratively computed over a 3-dimensional grid to look for an optimal solution that matches closely with the observed average MEG spectra, and the parameters resulting in the highest Pearson's correlation between power spectra are shown here.}
    \label{fig:grid_search}
\end{figure}

Figure \ref{fig:oscillator_full} shows the oscillator model solutions with MCMC sampler's posterior means for each parameter. Here, we only focused on the three parameters affecting oscillatory frequency and Hopf bifurcation point. While all parameters received non-informative flat priors, the samplers arrived at posterior distributions based on the log likelihood function in \ref{eq:ll} for average MEG power spectrum. We initiated our samplers under two conditions: default parameter values as described in \cite{muldoon_stimulation-based_2016} ($\tau_{e/i} = 8$ and $P=1.25$) or near a 10Hz oscillatory Hopf bifurcation point ($\tau_e = 3.0$, $\tau_i = 3.6$, and $P=1.1$). Under both scenarios, we see wide confidence intervals for both $\tau_i$ and $P$, despite $\tau_e$ having a narrower distribution, the samplers for both $\tau_e$ and $\tau_i$ did not accept parameters far away from their initial positions. Moreover, $\tau_i$ seems to have more than one highly probable value. Using the posterior means as model parameter inputs, the simulation produced a power spectrum with 15Hz peak and subsequent harmonic peaks at 30 and 45 Hz when initiated from default values. While the most notable peak in a human MEG spectrum is the alpha peak around 10Hz, the likelihood maximization mechanism arrived at a solution that captured the 10Hz alpha peak only when initiated near a 10Hz oscillatory regime. This model realization also produces many secondary higher harmonics which are not present in empirical spectra.

States of quiescence, transience, steady-state, and limit cycle in dynamical systems used by NMMs are clearly illustrated and reviewed in (\cite{breakspear_dynamic_2017}) and (\cite{sanz-leon_mathematical_2015}), where small changes in model parameters or initial conditions can affect the behavior of the model output - indicating the model's excessive sensitivity to parameters. Accordingly, our samplers also appeared to be stuck in a certain regime and reject samples that are outside of the preset limit cycle regime as set by default parameters. Figure \ref{fig:grid_search} shows the 6 most closely-matching spectra found by exhaustive grid search. These results suggest that there exist different sets of parameters that can produce oscillations at any of the notable frequency peaks, and highlight the problem of identifiability. We see two sets of parameters producing notable peaks at 20Hz, and a set of parameter producing a 15Hz oscillation that is different from the set obtained from MCMC sampling. 

These results highlight two different problems in inference: the inability to escape initial regime or local minimum; and the presence of several equally good local minima that produce widely divergent behavior.

\begin{figure}
    \centering
    \captionsetup{justification=centerlast}
    \includegraphics[width=\textwidth]{../figures/chapter3/oscillator_periodic_10hz.png}
   \caption{MCMC sampling of posterior distribution when maximizing likelihood to average periodic power spectrum ($L_{\textrm{PSD}}$).}
    \caption*{Corner plot of the posterior distributions for parameters $\tau_e$, $\tau_i$, and $P$ when initiating from default values (\textbf{A}) or Hopf bifurcation point (\textbf{B}) showing the probability densities of accepted parameter samples. \textbf{C} and \textbf{D} illustrates the average MEG spectrum (green) alongside the oscillator model spectra (blue) simulated with the posterior mean values shown from the corner plots above.}
    \label{fig:oscillator_periodic}
\end{figure}

\subsubsection{Fitting to spectral peaks instead of wideband spectra}
A broadband frequency spectrum contains a mixture of both a periodic component, and an aperiodic component ($\frac{1}{f}$-like fall off) that does not contribute to frequency-specific features \cite{donoghue_parameterizing_2020}. Since our oscillator model can only produce one principal frequency, we implemented the \emph{fitting oscillations \& one over f} (FOOOF) algorithm from Donoghue et al. \cite{donoghue_parameterizing_2020} to obtain a periodic frequency power spectrum. Figure \ref{fig:oscillator_periodic} shows the same posterior sampling procedure's results when maximizing likelihood to only the principal periodic component of the spectrum, and the bottom panels show the average MEG and model-simulated spectrum without the aperiodic component. Changing the objective function from the full frequency spectrum to the periodic frequency spectrum changed the parameter space landscape. In this periodic frequency spectrum objective function sampling regime, we see that the samplers were able to explore a much wider parameter range and did not get stuck in the initial regime. However, the $95\%$ confidence intervals around the posterior means for both time constant parameters are large, with upper bounds of about $+4$ and lower bounds of about $-3$. Suggesting there is still large uncertainty even if a point estimate method for parameter inference was implemented, especially with parameters $\tau_i$ and $P$ showing hints of bimodal distributions. Lastly, despite a smoother surface for the samplers, the final posterior means did not produce spectra that reproduced most notable frequency peaks in the observed MEG spectrum for either initial condition. Similar to previous results, all inferred local models appear to show very high level of secondary harmonics which are not observed in empirical spectra. 


\begin{figure}[htbp]
    \centering
    \includegraphics[scale=0.6]{../figures/chapter3/p_behavior.png}
    \caption{Network model behavior in response to external driving force}
    \caption*{Panels showing network model's time course, frequency spectrum, and coherence functional connectivity from top to bottom with increasing external driving force parameter $P$. Simulations are performed with default parameter values and $c_5 = 1.5$, the model is dominated by noise at low $P$, but switches to an oscillatory regime when $P$ crosses the Hopf bifurcation value. The example time course is shown for one brain region only, whereas the frequency spectrum is shown for all brain regions.}
    \label{fig:p_behavior}
\end{figure}

\begin{figure}[htbp]
    \caption{Network Wilson Cowan model sampling results for one representative subject.}
    \caption*{Top row shows the results for coherence maximum likelihood sampling, broadband AEC sampling in the middle, and bottom row shows the results for narrowband AEC maximum likelihood sampling. Left column shows the sampled posterior distributions for the global coupling parameter $c_5$, with the sampled mean and 95\% confidence intervals displayed. The middle column shows the network model simulated FC matrices with the posterior mean, and right column shows the scatter plot and linear regression line for the FC matrix entries. Both parameter posteriors achieved near zero slope for the linear fit.}
    \label{fig:networkc5}
\end{figure}
\clearpage
\begin{figure}[h!]
	\ContinuedFloat
	\captionsetup{labelformat=adja-page}
    \centering
    \includegraphics[width=\textwidth]{../figures/chapter3/network_c5_fits.png}
    \caption[]{}
\end{figure}


\subsection{Network Model Performance}
Existing literature expanding neural mass models to the network level fixes the local parameters of neural masses ($c_1$, $c_2$, $c_3$, and $c_4$) to be equal at all nodes in the network. Hence these identical oscillators can only produce diverse dynamics because of noisy input, heterogeneous connectome coupling and concomitant delays. For fMRI modeling, a Balloon-Windkessel hemodynamic model \cite{buxton_dynamics_1998, friston_nonlinear_2000} is usually layered on top of the NMMs for parameter optimization (For example, see \cite{Zimmermann2018}). This adds another set of model parameters and abstractions to describing observed functional phenomenon with mean field models. On the other hand, encephalography based modeling wraps another metric on top of the NMM outputs, such as kuramoto coupling parameters in \cite{Deco2009}.  Here we will focus on the Wilson-Cowan model only, examining whether they are good basis for network mdoeling.

\subsubsection{Effect of global parameters}
First we demonstrate the effect of external driving force $P$ on the networked model's time course, spectra and network structure (FC) in Figure \ref{fig:p_behavior}, using default values for all parameters. With increasing $P$, the networked system transitions from uncorrelated activity to oscillatory behavior. The latter point is better observed in the coherence FC matrices shown at the bottom. Interestingly, FC became over-saturated if the value of $P$ deviated far from the default operating range (e.g. $P>1.5$). Next, we show a similar set of analysis in Figure \ref{fig:c5_behavior}, where we vary global coupling $c_5$ while holding all other parameters constant and $P$ is kept at the Hopf bifurcation point. Surprisingly, varying $c_5$ does not change the time course or shift the dominant oscillatory component of the spectra at all. But as the connectomes' connections contributes more to the model dynamics, coherence FC drastically changes despite minuscule detectable changes to the underlying dynamics.

\begin{figure}[htbp]
    \centering
    \captionsetup{justification=centerlast}
    \includegraphics[width=\textwidth]{../figures/chapter3/individual_c5_spectra.png}
    \caption{Comparison between MEG spectra and network model simulated spectra for 4 subjects.}
    \caption*{Model simulated spectra were computed with the posterior mean for global coupling parameter $c_5$ after MCMC sampling. The average spectra from all cortical brain regions is shown as lines, and the standard deviation summarized from all regions is shown as shaded fillings. Source localized MEG spectra is shown in blue, coherence parameter simulated spectra is shown in red, narrowband and broadband AEC parameter simulated spectra are shown in black and green respectively. All spectras were normalized by their minimum and maximum values to be between 0 and 1 for equal visualization scale.}
    \label{fig:c5_spectra}
\end{figure}

\subsubsection{Inference of global coupling $c_5$ depends on objective function}

Following existing network modeling publications, we first performed inference of the global coupling parameter $c_5$ with MCMC. We fixed the time constants $\tau_e$ and $\tau_i$ so that each oscillator has a base oscillating frequency of near 10Hz, and we fixed $P = 1.1$ to be right below the Hopf bifurcation point so the network's dynamics is purely driven by connectivity. The top panel of Figure \ref{fig:networkc5} shows the second order statistics - coherence and AEC - of source localized MEG in the $\alpha$ band for the $68$ cortical regions parcellated according to the Desikan-Killiany atlas \cite{Desikan2006}. Bottom of Figure \ref{fig:networkc5} shows the posterior distributions of $c_5$ under three likelihood functions associated with fitting for COH (top) and AEC (middle) and alpha band AEC (bottom). While MCMC produced reasonably concentrated posteriors with narrow confidence intervals in all three cases, the resulting FC matrices do not resemble empirical FC matrices. The hemispheric block structure and sparsity seen in MEG coherence FC are absent in model COH. Simulated AEC is appropriately sparse but also does not resemble MEG AEC. The scatter plots shown alongside also do not support successful prediction of either COH or AEC. Note also that the objective being fit - AEC vs COH dramatically changes the optimal value of inferred $c_5$. Coherence and narrowband AEC fitting led to a lower estimated global coupling value, $c_5 \approx 1.5-1.6$ , whereas fitting to AEC (green) led to higher $c_5 \approx 9$. This is highly problematic, and further highlights the extreme parameter sensitivity of coupled NMMs - this time under differing objective functions.

\subsubsection{Networked metric derived frequency spectrum}
At its essence, FC matrices are second order statistics computed from time course activity over time, whether recordings like MEG or simulated activity with our network NMM. And here we see that changing the maximum likelihood definition or objective function in parameter inference drastically affects the gradients and eventual posterior parameter values. For modeling based analysis to claim its parameters describe the full relationship between some phenomenon and brain activity, we believe the network model should reproduce characteristic spectral patterns as observed in MEG recordings.

We explored whether the networked model inferred to fit the second order FC is capable of reproducing the primary first order statistics, i.e. node-evel power spectra. As shown in the four individual cases of Figure \ref{fig:c5_spectra}, connectome coupling with delays and noise certainly expanded the networked model's spectral repertoire. Recall that the local time constants were previously fixed to produce oscillations of 10Hz, hence the networked spectra using global coupling $c_5$ inferred using FC also produces an alpha peak. Interestingly, optimal $c_5$ fit to $\alpha$-band AEC produced nearly identical spectra up to $\alpha$ frequencies in all brain regions, and only showed regional diversity in the $\beta$ band. Unfortunately, none of the models inferred on FC can be said to properly reproduce regional wideband power spectra. The only one that looks remotely plausible is the one fitted to COH.

\subsubsection{Full inference of networked NMM}
The above results demonstrate that the inference approach adopted in current literature, of fixing some parameters to produce the correct oscillation frequency, and others to match second order FC, is problematic, and does not in fact reproduce first order statistics of node-level wideband spectra. Therefore we now attempt a full inference of all model parameters starting from their default values as listed in the Table \ref{tab:oscillator_parameters}. We expect that increasing the dimensionality of the parameter space can improve model performance, but traversing between oscillatory, quiescence, and transience activity regimes during sampling may cause the samplers to be stuck in local minima. We first initialize $\tau_e$ and $\tau_i$ to $8$ms with a small variation for each sampler, and repeated MCMC. These initial model parameter values are those used in \cite{muldoon_stimulation-based_2016}, where a 20Hz limit cycle regime occurs. In this high dimensional non-linear network model, inferring high number of parameters with a non-convex objective function gradient is difficult, and was not performed in \cite{muldoon_stimulation-based_2016}, who assumed the 20Hz limit cycle parameter regime to be "biophysiological". Here we want to check if the MCMC samplers can find posterior parameter distributions that resemble observed MEG data.

Figure \ref{fig:coh_hopf} and Figure \ref{fig:aec_hopf} illustrates the sampler's inability to survey the 4 dimensional parameter space set by the network model for alpha band coherence or AEC. In Figure \ref{fig:coh_hopf}, neither $\tau_e$ or $\tau_i$ escaped their initial positions near 8ms. Global coupling $c_5$ and external driving force $P$ had high uncertainties as indicated by their 95\% confidence intervals. As mentioned above, the initialization puts the model into a 20Hz oscillatory regime, and the samplers were not able to arrive at a viable solution for $\alpha$ band coherence. The simulated coherence shown in Figure \ref{fig:coh_hopf} in combination with the spectra shown in Figure \ref{fig:psd_hopf} shows that there was no oscillations or variability near 10Hz.

Similarly, Figure \ref{fig:aec_hopf} shows the same failure of samplers escaping its initial positions. However, in this case, the posterior distributions for all parameters had extremely narrow 95\% confidence intervals. Despite this certainty, the simulated AEC matrix had much higher values than, and little to no significant correlation with, empirical AEC. The corresponding power spectra (green in Figure \ref{fig:psd_hopf}) show no $\alpha$ peak, being unable to move away from the initial 20Hz oscillations. Two subjects' model spectra showed no variability between regions and no obvious peaks whatsoever. Lastly, the spectra produced by parameters sampled for alpha band AEC were also stuck near the initial values, producing similarly implausible spectra as other fits described above. 

\begin{figure}[htbp]
    \centering
    \captionsetup{justification=centerlast}
    \includegraphics[width=\textwidth]{../figures/chapter3/individual_hopf_spectra.png}
   \caption{Comparison between MEG spectra and posterior mean global parameters simulated spectra for 4 subjects.}
    \caption*{Model simulated spectra were computed with the posterior means for ${\tau_e, \tau_i, c_5, P}$ after MCMC sampling. The average spectra from all cortical brain regions is shown as lines, and the standard deviation summarized from all regions is shown as shaded fillings. Source localized MEG spectra is shown in blue, coherence parameters simulated spectra is shown in red, narrowband and broadbanc AEC parameters simulated spectra is shown in black and green respectively. All spectras were normalized by their minimum and maximum values to be between 0 and 1 for equal visualization scale.}
    \label{fig:psd_hopf}
\end{figure}

Based on the existing literature's avoidance of this parameter fitting procedure for network NMMs, and the fact that we are implementing a barebones approach with no adjustments to the mean firing rate model, we did not expect the network NMM to perform well in capturing neural activity statistics. Typically, a more specified model is required to produce any meaningful statistics. We've shown that a typical oscillator unit produces limit cycle activity at a single frequency as specified by the model parameters, and adding a network component to the model does not easily translate to network metrics being produced by the network model. Furthermore, the existing practice of setting model parameters near an oscillatory regime and searching for parameters that fits some neural activity metric well doesn't take into account the problem of unidentifiable parameters. Lastly, network models are high in dimensionality, making parameter posterior sampling a consuming and unpredictable exercise. And by limiting every node to have identical parameter values to decrease parameter inference complexity is not biologically realistic and produces irrelevant results. 

\section{Discussion}
\subsection{NMM Based Analysis}
Parameter inference of a full brain network neural mass model is rarely attempted in the computational neuroscience field. The complexity due to their nonlinearity and network size with numerous delays, combined with the tangled nature of neurological recordings, makes the optimization of these NMMs a nearly impossible task. The first thing we've shown here is that an oscillating Wilson-Cowan neural population has a limit cycle activity for a specific frequency given a specific set of parameters. Extending this model to the network scale by introducing delays and connectivity, but fixing all nodes to have identical parameters for computational tractability does not necessarily provide the broadband spectrum that is characteristic of observed encephalography recordings.

In most NMM analysis (see Table \ref{tab:nmm_pubs}), the comparisons are made to fMRI BOLD functional connectivity, which has limited temporal resolution, and recorded neural dynamics are limited to below 1Hz. Whereas NMMs mean firing rate outputs are simulated with millisecond time-steps, to compensate for the mismatch in data type and temporal resolution, a Balloon-Windkessel hemodynamics model \cite{friston_nonlinear_2000, deco_resting-state_2013} is used to transform the model outputs to BOLD signals (For example, see \cite{deco_resting-state_2013, deco_how_2014}) for functional connectivity comparison. Practically, parameters for the NMM is first fitted either by exhaustive grid search or constrained optimization, followed by another model fitting for the BOLD signal transformation. The two layers or model fitting leads to low interpretability of final parameters, and low correlations with high variances in parameter distribution on the group level leads to uncertainties about any result.

In other publications, for the sake of computational tractability, a more simplistic Wilson Cowan model variant with more varied model behavior is used as an alternative (For example, see \cite{Deco2009}, where an additional Kuramoto coupling parameter is required for spectrum computation). In this model, the sigmoidal activation function is simplified to one term, and its inputs are generalized to include network level driving forces and noise. Bringing into question the meaning behind a nonlinear sub-population neuron activation function for network level inputs. In Muldoon et al.'s work on network controllability \cite{muldoon_stimulation-based_2016}, the original network model was made to oscillate at 20Hz, and no model fitting was performed, only changes in functional network properties based on a single nodal stimulation with the driving force parameter was measured. Again, based on our results with the same model implementation and identical parameter regimes, a network of identical oscillators will not provide simulated functional network metrics that closely resemble those of a realistic brain. Functional connectivity metrics and network activity will undoubtedly change according to network connections, but the parameters producing the accepted functional outputs may not produce an acceptable spectra. Moreover, it is unclear if there is an optimal parameter regime that is suitable for a given brain state due to parameter unidentifiability issues as discussed by numerous works \cite{hartoyo_parameter_2019, chis_relationship_2016, villaverde_observability_2019}.

Overall, it is no surprise that the promise of personalized diagnosis with model based analysis has been overtaken by the capabilities of deep learning or the analytical efficiencies of linear models \cite{Becker2018, raj_spectral_2020}. Deep learning neural networks takes advantage of repeated and chained linear regression units with rectified linear activation units (ReLu) to make extremely fast classifications of data, and it has already been shown to produce high accuracy for biological phenomenon \cite{pulvermuller_biological_2021, parmar_spatiotemporal_2020}. In this framework, interpolating high dimensional data for a given classification or embedding is made possible by the massive flexibility of layered linear units, and is already superior than any nonlinear NMMs in terms of training speed and prediction power. In fact, finding a global minimum to the massive parameter space of deep neural networks is frowned upon due to generalizability, and training of complex parameter spaces is made efficient by backpropagation of gradients. On the other hand, Linear models such as the works cited above transforms dynamical systems to the Fourier domain and uses structural eigen basis to relate functional patterns to a given structural connectome. These efforts provide models that are low-dimensisonal, hierarchical across spatial scales, and efficient to compute as the analytical models do not require step adaptive integrators. The trade offs over linear and nonlinear macroscopic models was recently examined by Nozari et al. \cite{nozari_is_2020}, whom also reported on the performance of nonlinear NMMs to fit neurodynamic time course data. In addition to reporting linear models outperforming nonlinear models on the macroscopic scale, their work also commented on the macroscopic brain properties that masks nonlinear dynamics. Together with our results, we believe it is evident that nonlinear NMMs are not the optimal model of choice for model-based macroscopic neurophysiological data analysis.

\subsection{MCMC Convergence \& Other Approaches}
In our results, we avoided the topic of convergence for our samplers. Convergence is often a difficult topic to discuss for MCMC sampling based analysis, because convergence can only be guaranteed for sample statistical problems with a high number of samples. For high dimensional model parameter inference, quality of the sampled posterior is often evaluated by acceptance ratio of samples and inspection of the posterior as compared to the prior. Additionally, statistics like the Gelman-Rubin statistic \cite{gelman_inference_1992} are not applicable to modern MCMC algorithms as the multi-samplers used for parallelization are not independent from each other. On the other hand, integrated autocorrelation time \cite{goodman_ensemble_2010} quantifies the effective number of independent samples needed and sampler efficiency. However, our sampling chains for all scenarios produced high acceptance rates and integrated autocorrelation times that required extremely large amounts of MCMC samples and weeks long computation times. This implies that the log likelihood ratios conditioning our parameter inference problem is not sufficently exploring the entirety of the parameter space. Our resulting weak fits with the fact that majority of accepted samples have low likelihoods suggest global sampling methods are not the proper approach for NMM parameter optimization. Secondly, the Wilson-Cowan network model parameters are not capable of describing the high dimensional features of functional neural recordings.

One may suggest that global parameter optimization methods with multiple local searches may improve our model fits. Approaches such as simulated annealing \cite{Kirkpatrick1983} or basin hopping \cite{Wales1997} may arrive at inferred parameters that provide better fits, but has their short comings. Firstly, these approaches provide point estimates of model parameters, ignoring any uncertainty in the case of complex parameter spaces that may have more than one possible solutions. In addition, while convergence for these algorithms can be determined by consecutive visits to the current  optimal solution, the solution is still sensitive to initialization, and there is no formal way of selecting optimization hyper-parameters such as tolerances, iterations, temperature, or cooling schedule (exploration scheme). Furthermore, these approaches do not provide any formalism for an objective function, and does not have the advantage of using a Bayesian framework which provides a set framework and a model evidence metric. 


\subsection{Dynamic Causal Modeling}
One popular model based analysis is dynamic causal modeling (DCM), these approaches focus on discovery of effective network connectivity, and the emphasis is placed on a few nodes of interest \cite{friston_network_2011}. Typically used for determining causality in fMRI data, this method aims to find the causal network that best supports the observed data as measured by Bayesian model evidence \cite{stephan_nonlinear_2008}. While the goal of DCM based studies are different from model based analysis of neural recordings, the insights gained from causality in small subnetworks of the brain with a formal framework is extremely valuable. However, this approach is made impractical for whole brain studies due to the number of evaluations and possible networks required to be considered. Furthermore, in the case of NMMs, the nonlinear nature of the model makes the model inversion problem extremely inefficient. Whereas DCM works typically takes advantage of fully connected network models that are easily invertable. 

\subsection{Variational Inference}
Variational inference is a statistical method used to approximate parameter posterior densities in Bayesian models, where parameters and their uncertainties are obtained through optimization rather than expensive sampling. The optimization is theoretically performed based on the gradients of a posterior distribution obtained through Baye's theorem. However, the partial derivatives culminating in the full parameter space gradient is intractable for macroscopic network NMMs, and current implementations of variational inference such as \emph{Edward2} \cite{tran2018simple} and \emph{PyMC3} \cite{Salvatier2016} uses a "black box" inference approach. While these approaches seem effective for simpler problems, the need to fully sample the posterior hinders the usage of these tools for network NMMs. In particular, a network model such as the Wilson Cowan model requires the integration of two sets of derivatives for every brain region. And additionally for each brain region, the algorithm is required to remember past solutions at all nodes, and interpolate the past solutions based on unique distance induced delays as assigned by the connectomes. This makes computation of one realization with minimal time steps extremely slow on CPU backends (several minutes), needing to sample thousands of solutions for the likelihood estimation per iteration is simply impossible when taking into account computing time. Moreover, efficient parameter optmization relies on convex structural properties of the problem to guarantee rapid convergence to a solution. But in the case of NMMs and their black-box objective functions, these properties cannot be theoretically determined. In our case of expensive objective functions, the strategy needs to restrict the exploration of the search space to remain computationally tractable, further crippling network model based approaches to exploring neural data.

\subsection{Challenges and Limitations}
We've already addressed the problem of MCMC requiring large numbers of samples for diversity and statistical validity, which is computationally expensive and often times not practical to achieve with network scale NMMs. To further add to the challenges, reliable estimations of functional connectivity maps require on the order of a minute worth of data. This finite data problem in source localized encephalography recordings is comprehensively explored by Sommariva et al. \cite{sommariva_comparative_2019}, concluding unsurprisingly that estimating functional connectivity is prone to errors with less data. Our numerical network NMM simulations of 2 seconds is on the low end of data length, and is certainly prone to unreliable functional connectivity outputs. This effect is further amplified if initialization of the delayed dynamical systems are not properly selected, as initial values affect the stationary points and stability of the oscillating system. We limited our simulation time to 2 seconds for the simple reason of practical computation time. Numerical integration of NMMs require time-steps below the millisecond to ensure accuracy at every time step. When more uncertainties from delayed inputs and noises at every network node is introduced, the integrators usually takes even smaller time steps, exponentially increasing the time needed to simulate one realization of the NMM. Therefore, parameter exploration poses immediate impossibilities, which is often commented on by published NMM works or avoided by simplifying the problem. 

\section{Conclusion}
The dimensionality and nonlinearity of network NMMs leads to low confidence for a given system to produce functional dynamics with desired properties, and subsequently compare these models for effective analysis. Additionally, there is no formal methodology for selecting initial values of the delayed dynamics or the initial positions of parameters. In the case of the Wilson-Cowan model, the mean firing rates of neuron sub-populations output is simply not appropriate for encephalography modality data modeling. Recordings of neural activity involves excitation driven currents or blood-oxygen dependent activity, the sensor level average activity we observe in data is not simply explained by firing rate models and more mechanistic details are required. In our work, we show that one of the widely adapted NMMs is specified for neuron population level firing rate studies of a specified frequency, extending such a model to the network scale does not allow accurate, reliable, or efficient optimization. Furthermore, second order connectivity statistics often does not encapsulate sufficient evidence for tuning of network model parameters. Overall, we believe claims of unidentifiable network NMM parameters as low dimensional descriptors of biophysiological data should be carefully examined. More effective alternatives in linear models and deep learning has already surpassed NMMs, and offers more insight into the embeddings of functional brain recordings.